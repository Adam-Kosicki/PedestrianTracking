{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the YOLOv9 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolov9e-seg.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize video source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video opened successfully!\n",
      "Video Frame Rate: 30.0 fps\n"
     ]
    }
   ],
   "source": [
    "# Define video source\n",
    "vid_path = \"./sources/one_two_ppl.mp4\"\n",
    "vid_cap = cv2.VideoCapture(vid_path)\n",
    "vid_fps = vid_cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# Check if the video was openened correctly\n",
    "if not vid_cap.isOpened():\n",
    "    print(\"Error opening video file.\")\n",
    "else:\n",
    "    print(\"Video opened successfully!\")\n",
    "    print(\"Video Frame Rate:\", str(vid_fps) + \" fps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define YOLO classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "PERSON = 0\n",
    "BIKE = 1\n",
    "CAR = 2\n",
    "MOTORCYCLE = 3\n",
    "BUS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process video source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 384x640 2 persons, 1054.2ms\n",
      "Speed: 2.5ms preprocess, 1054.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "tensor([0.])\n",
      "None\n",
      "tensor([0.])\n",
      "frame: 1\n",
      "\n",
      "0: 384x640 2 persons, 1031.9ms\n",
      "Speed: 1.7ms preprocess, 1031.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "tensor([1.])\n",
      "tensor([0.])\n",
      "class: 0\n",
      "id 1\n",
      "tensor([2.])\n",
      "tensor([0.])\n",
      "class: 0\n",
      "id 2\n",
      "frame: 2\n",
      "\n",
      "0: 384x640 2 persons, 1041.5ms\n",
      "Speed: 1.8ms preprocess, 1041.5ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "tensor([1.])\n",
      "tensor([0.])\n",
      "class: 0\n",
      "id 1\n",
      "tensor([2.])\n",
      "tensor([0.])\n",
      "class: 0\n",
      "id 2\n",
      "frame: 3\n",
      "\n",
      "0: 384x640 2 persons, 1013.4ms\n",
      "Speed: 1.5ms preprocess, 1013.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "tensor([1.])\n",
      "tensor([0.])\n",
      "class: 0\n",
      "id 1\n",
      "tensor([2.])\n",
      "tensor([0.])\n",
      "class: 0\n",
      "id 2\n",
      "frame: 4\n",
      "\n",
      "0: 384x640 2 persons, 1136.0ms\n",
      "Speed: 1.6ms preprocess, 1136.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "tensor([1.])\n",
      "tensor([0.])\n",
      "class: 0\n",
      "id 1\n",
      "tensor([2.])\n",
      "tensor([0.])\n",
      "class: 0\n",
      "id 2\n",
      "frame: 5\n",
      "\n",
      "0: 384x640 2 persons, 1020.1ms\n",
      "Speed: 1.5ms preprocess, 1020.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "tensor([1.])\n",
      "tensor([0.])\n",
      "class: 0\n",
      "id 1\n",
      "tensor([2.])\n",
      "tensor([0.])\n",
      "class: 0\n",
      "id 2\n",
      "frame: 6\n",
      "\n",
      "0: 384x640 2 persons, 1098.1ms\n",
      "Speed: 1.5ms preprocess, 1098.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "tensor([1.])\n",
      "tensor([0.])\n",
      "class: 0\n",
      "id 1\n",
      "tensor([2.])\n",
      "tensor([0.])\n",
      "class: 0\n",
      "id 2\n",
      "frame: 7\n",
      "\n",
      "0: 384x640 2 persons, 1010.2ms\n",
      "Speed: 2.1ms preprocess, 1010.2ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "tensor([1.])\n",
      "tensor([0.])\n",
      "class: 0\n",
      "id 1\n",
      "tensor([2.])\n",
      "tensor([0.])\n",
      "class: 0\n",
      "id 2\n",
      "frame: 8\n",
      "\n",
      "0: 384x640 2 persons, 1163.7ms\n",
      "Speed: 2.1ms preprocess, 1163.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "tensor([1.])\n",
      "tensor([0.])\n",
      "class: 0\n",
      "id 1\n",
      "tensor([2.])\n",
      "tensor([0.])\n",
      "class: 0\n",
      "id 2\n",
      "frame: 9\n",
      "\n",
      "0: 384x640 2 persons, 1044.8ms\n",
      "Speed: 1.5ms preprocess, 1044.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "tensor([1.])\n",
      "tensor([0.])\n",
      "class: 0\n",
      "id 1\n",
      "tensor([2.])\n",
      "tensor([0.])\n",
      "class: 0\n",
      "id 2\n",
      "frame: 10\n",
      "\n",
      "0: 384x640 2 persons, 1445.8ms\n",
      "Speed: 2.1ms preprocess, 1445.8ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "tensor([1.])\n",
      "tensor([0.])\n",
      "class: 0\n",
      "id 1\n",
      "tensor([2.])\n",
      "tensor([0.])\n",
      "class: 0\n",
      "id 2\n",
      "frame: 11\n",
      "\n",
      "0: 384x640 2 persons, 1559.4ms\n",
      "Speed: 3.1ms preprocess, 1559.4ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "tensor([1.])\n",
      "tensor([0.])\n",
      "class: 0\n",
      "id 1\n",
      "tensor([2.])\n",
      "tensor([0.])\n",
      "class: 0\n",
      "id 2\n",
      "frame: 12\n",
      "\n",
      "0: 384x640 2 persons, 1466.9ms\n",
      "Speed: 3.8ms preprocess, 1466.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "tensor([1.])\n",
      "tensor([0.])\n",
      "class: 0\n",
      "id 1\n",
      "tensor([2.])\n",
      "tensor([0.])\n",
      "class: 0\n",
      "id 2\n",
      "frame: 13\n",
      "\n",
      "0: 384x640 2 persons, 1447.2ms\n",
      "Speed: 1.8ms preprocess, 1447.2ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "tensor([1.])\n",
      "tensor([0.])\n",
      "class: 0\n",
      "id 1\n",
      "tensor([2.])\n",
      "tensor([0.])\n",
      "class: 0\n",
      "id 2\n",
      "frame: 14\n",
      "\n",
      "0: 384x640 2 persons, 1411.8ms\n",
      "Speed: 2.1ms preprocess, 1411.8ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "tensor([1.])\n",
      "tensor([0.])\n",
      "class: 0\n",
      "id 1\n",
      "tensor([2.])\n",
      "tensor([0.])\n",
      "class: 0\n",
      "id 2\n",
      "frame: 15\n",
      "\n",
      "0: 384x640 2 persons, 1252.1ms\n",
      "Speed: 2.2ms preprocess, 1252.1ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "tensor([1.])\n",
      "tensor([0.])\n",
      "class: 0\n",
      "id 1\n",
      "tensor([2.])\n",
      "tensor([0.])\n",
      "class: 0\n",
      "id 2\n",
      "frame: 16\n",
      "\n",
      "0: 384x640 2 persons, 1490.2ms\n",
      "Speed: 2.4ms preprocess, 1490.2ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "tensor([1.])\n",
      "tensor([0.])\n",
      "class: 0\n",
      "id 1\n",
      "tensor([2.])\n",
      "tensor([0.])\n",
      "class: 0\n",
      "id 2\n",
      "frame: 17\n",
      "\n",
      "0: 384x640 2 persons, 1471.7ms\n",
      "Speed: 2.2ms preprocess, 1471.7ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "tensor([1.])\n",
      "tensor([0.])\n",
      "class: 0\n",
      "id 1\n",
      "tensor([2.])\n",
      "tensor([0.])\n",
      "class: 0\n",
      "id 2\n",
      "frame: 18\n",
      "\n",
      "0: 384x640 2 persons, 1239.2ms\n",
      "Speed: 2.2ms preprocess, 1239.2ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "None\n",
      "tensor([0.])\n",
      "None\n",
      "tensor([0.])\n",
      "frame: 19\n",
      "\n",
      "0: 384x640 1 person, 1525.8ms\n",
      "Speed: 2.0ms preprocess, 1525.8ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "tensor([3.])\n",
      "tensor([0.])\n",
      "class: 0\n",
      "id 3\n",
      "frame: 20\n",
      "\n",
      "0: 384x640 2 persons, 1364.4ms\n",
      "Speed: 2.3ms preprocess, 1364.4ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "tensor([3.])\n",
      "tensor([0.])\n",
      "class: 0\n",
      "id 3\n",
      "tensor([4.])\n",
      "tensor([0.])\n",
      "class: 0\n",
      "id 4\n",
      "frame: 21\n",
      "\n",
      "0: 384x640 2 persons, 1351.3ms\n",
      "Speed: 2.0ms preprocess, 1351.3ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "tensor([3.])\n",
      "tensor([0.])\n",
      "class: 0\n",
      "id 3\n",
      "tensor([4.])\n",
      "tensor([0.])\n",
      "class: 0\n",
      "id 4\n",
      "frame: 22\n",
      "\n",
      "0: 384x640 2 persons, 1540.8ms\n",
      "Speed: 2.1ms preprocess, 1540.8ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "tensor([3.])\n",
      "tensor([0.])\n",
      "class: 0\n",
      "id 3\n",
      "tensor([4.])\n",
      "tensor([0.])\n",
      "class: 0\n",
      "id 4\n",
      "frame: 23\n",
      "\n",
      "0: 384x640 2 persons, 1492.2ms\n",
      "Speed: 2.1ms preprocess, 1492.2ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "tensor([3.])\n",
      "tensor([0.])\n",
      "class: 0\n",
      "id 3\n",
      "tensor([4.])\n",
      "tensor([0.])\n",
      "class: 0\n",
      "id 4\n",
      "frame: 24\n",
      "\n",
      "0: 384x640 2 persons, 1322.7ms\n",
      "Speed: 2.8ms preprocess, 1322.7ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "tensor([3.])\n",
      "tensor([0.])\n",
      "class: 0\n",
      "id 3\n",
      "tensor([4.])\n",
      "tensor([0.])\n",
      "class: 0\n",
      "id 4\n",
      "frame: 25\n",
      "\n",
      "0: 384x640 2 persons, 1516.5ms\n",
      "Speed: 2.4ms preprocess, 1516.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "tensor([3.])\n",
      "tensor([0.])\n",
      "class: 0\n",
      "id 3\n",
      "tensor([4.])\n",
      "tensor([0.])\n",
      "class: 0\n",
      "id 4\n",
      "frame: 26\n",
      "\n",
      "0: 384x640 2 persons, 1476.2ms\n",
      "Speed: 2.1ms preprocess, 1476.2ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "tensor([3.])\n",
      "tensor([0.])\n",
      "class: 0\n",
      "id 3\n",
      "tensor([4.])\n",
      "tensor([0.])\n",
      "class: 0\n",
      "id 4\n",
      "frame: 27\n",
      "\n",
      "0: 384x640 2 persons, 1356.2ms\n",
      "Speed: 1.7ms preprocess, 1356.2ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "tensor([3.])\n",
      "tensor([0.])\n",
      "class: 0\n",
      "id 3\n",
      "tensor([4.])\n",
      "tensor([0.])\n",
      "class: 0\n",
      "id 4\n",
      "frame: 28\n",
      "\n",
      "0: 384x640 2 persons, 1447.8ms\n",
      "Speed: 2.4ms preprocess, 1447.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "tensor([3.])\n",
      "tensor([0.])\n",
      "class: 0\n",
      "id 3\n",
      "tensor([4.])\n",
      "tensor([0.])\n",
      "class: 0\n",
      "id 4\n",
      "frame: 29\n",
      "\n",
      "0: 384x640 2 persons, 1267.2ms\n",
      "Speed: 2.1ms preprocess, 1267.2ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "tensor([3.])\n",
      "tensor([0.])\n",
      "class: 0\n",
      "id 3\n",
      "tensor([4.])\n",
      "tensor([0.])\n",
      "class: 0\n",
      "id 4\n",
      "frame: 30\n",
      "\n",
      "0: 384x640 2 persons, 1352.2ms\n",
      "Speed: 1.9ms preprocess, 1352.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "tensor([3.])\n",
      "tensor([0.])\n",
      "class: 0\n",
      "id 3\n",
      "tensor([4.])\n",
      "tensor([0.])\n",
      "class: 0\n",
      "id 4\n",
      "frame: 31\n",
      "\n",
      "0: 384x640 2 persons, 1472.5ms\n",
      "Speed: 2.1ms preprocess, 1472.5ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "tensor([3.])\n",
      "tensor([0.])\n",
      "class: 0\n",
      "id 3\n",
      "tensor([4.])\n",
      "tensor([0.])\n",
      "class: 0\n",
      "id 4\n",
      "frame: 32\n",
      "\n",
      "0: 384x640 (no detections), 1383.7ms\n",
      "Speed: 2.1ms preprocess, 1383.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "frame: 33\n",
      "{'class_0_idx_1': 0.06666666666666667, 'class_0_idx_2': 0.06666666666666667, 'class_0_idx_3': 0.6666666666666666, 'class_0_idx_4': 0.7}\n"
     ]
    }
   ],
   "source": [
    "ped_times = {}\n",
    "\n",
    "while vid_cap.isOpened():\n",
    "\tsuccess, frame = vid_cap.read()\n",
    "\tif not success:\n",
    "\t\tbreak\n",
    "\n",
    "\t# Perform detection and tracking\n",
    "\tresults = model.track(frame, persist=True, conf=0.2, classes=[PERSON, BIKE], iou=0.5, show=False, tracker=\"bytetrack.yaml\")\n",
    "\n",
    "\t# Print frame\n",
    "\tframe_num = int(vid_cap.get(cv2.CAP_PROP_POS_FRAMES))\n",
    "\n",
    "\t# Get annotated frame and display it\n",
    "\t# annotated_frame = results[0].plot()\n",
    "\t# cv2.imshow('YOLOv9 Tracking', annotated_frame)\n",
    "\tfor i, r in enumerate(results):\n",
    "\t\tfor index, box in enumerate(r.boxes):\n",
    "\t\t\t# id of object\n",
    "\t\t\tprint(box.id)\n",
    "\t\t\tprint(box.cls)\n",
    "\t\t\tif(box.id and box.cls[0] != None):\n",
    "\t\t\t\t# print(box.id)\n",
    "\t\t\t\t# print(box.cls)\n",
    "\t\t\t\ttracker_id = int(box.id)\n",
    "\t\t\t\ttracker_cls = int(box.cls[0])\n",
    "\t\t\t\tprint(\"class:\", tracker_cls)\n",
    "\t\t\t\tprint(\"id\", tracker_id)\n",
    "\n",
    "\t\t\t\tobj_idx = \"class_\" + str(tracker_cls) + \"_idx_\" + str(tracker_id)\n",
    "\t\t\t\tif(not(obj_idx in ped_times)):\n",
    "\t\t\t\t\tped_times[obj_idx] = frame_num / vid_fps\n",
    "    \n",
    "\tprint(\"frame:\", frame_num)\n",
    "\n",
    "print(ped_times)\n",
    "\n",
    "\t# # Press 'q' to exit\n",
    "\t# if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "\t# \tbreak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Release Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.670000\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(str(datetime.timedelta(seconds=0.67, )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class_0': 123, 'class_1': 2}\n"
     ]
    }
   ],
   "source": [
    "ex_dict = {}\n",
    "ex_dict[\"class_0\"] = 123\n",
    "ex_dict[\"class_1\"] = 2\n",
    "print(ex_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_str = open(\"example_print_file.txt\", \"w\")\n",
    "save_str.write(str(ex_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class_0': 123, 'class_1': 2}\n"
     ]
    }
   ],
   "source": [
    "print(str(ex_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_str.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
